# -*- coding: utf-8 -*-
"""Copy of Week1_HW_Setup(ANNs).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hT87Hm9yicD-H4VJgQZzqe1Hf3KD6wf0

**<h1 style="color:red"> MAKE A COPY OF THIS NOTEBOOK TO START WORKING</h1>**

Import Statements
"""

import os
import numpy as np
import pandas as pd
import glob
import matplotlib.pyplot as plt

# CODE HERE (add more imports)
import torch
import torch.nn as nn

import torchvision
from torchvision import datasets
from torchvision.transforms import ToTensor
from torch.utils.data import DataLoader, Subset, Dataset
from tqdm import tqdm

"""#Import the Dataset

Kaggle is an open source dataset library. We will pull a dataset from Kaggle using the kagglehub API; this allows us to import datasets right into our google colab notebook without having to generate a API key. This is the link to the dataset if you would like to check it out!

https://www.kaggle.com/datasets/datamunge/sign-language-mnist/data

<img src="https://storage.googleapis.com/kaggle-datasets-images/3258/5337/0dade1b95b22cceac471b309fc8a8f63/dataset-cover.png" alt="Sign Language Dataset">

#### Before we import the dataset, let's create a dictionary that matches a numerical index to one of the letters that is being signed.

Tips:
- Start the index at 0 (so '0': 'A' should be the first entry in the dictionary)
- The letter J isn't included in this dataset, so skip this (should have 25 entries in dictionary in total; indices from 0 to 24).
"""

num_to_letter = {'0':'A', '1':'B', '2':'C', '3':'D', '4':'E', '5':'F', '6':'G', '7':'H', '8':'I', '9':'K', '10':'L', '11':'M', '12':'N', '13':'O', '14':'P', '15':'Q', '16':'R', '17':'S', '18':'T', '19':'U', '20':'V', '21':'W', '22':'X', '23':'Y', '24':'Z', }

"""#### Import Kaggle & the Dataset"""

!pip install --upgrade kagglehub

import kagglehub

# Download latest version
path = kagglehub.dataset_download("datamunge/sign-language-mnist") # You may ignore the error regarding the KaggleHub version if it shows

print("Path to dataset files:", path)

print(os.listdir(path))

train_dir = os.path.join(path, "sign_mnist_train.csv")
test_dir = os.path.join(path, "sign_mnist_test.csv")

train_df=pd.read_csv(train_dir)
test_df=pd.read_csv(test_dir)

train_images=train_df.drop('label',axis=1).values.reshape((-1,28,28,1))
train_labels=train_df['label'].values

test_images=test_df.drop('label',axis=1).values.reshape((-1,28,28,1))
test_labels=test_df['label'].values

print(train_images.shape)
print(train_labels.shape)
print(test_images.shape)
print(test_labels.shape)

# One image's shape is
train_images[0].shape

"""Can you explain what these  numbers mean?

#Visualize the Data

Visualize some images from `train_images` and `test_images` and then look at the corresponding labels (Keep in mind, they are numbers!)
>When interpreting what the numbers are look at the image at the top of the notebook. There are

Use `plt.imshow(Put the image here)` -> Accepts (Height, Width, Channel)
>Plug in an index of data
"""

# CODE HERE (set up image_num with text input)
image_num = 1000 #@param {type:"raw"}

# CODE HERE (print shape of image)
print(train_images[image_num].shape)

# CODE HERE (plot the image)
plt.imshow(train_images[image_num])

np.unique(train_labels)

"""#Create the Model"""

class MLP(nn.Module):
  def __init__(self, input_layer=784, output=25):
    # CODE HERE (remove the pass afterwards, use Sequential API)
    super().__init__()
    self.layers = nn.Sequential(
        nn.Flatten(),
        nn.Linear(input_layer, 256),
        nn.ReLU(),
        nn.Linear(256, 128),
        nn.ReLU(),
        nn.Linear(128, 32),
        nn.ReLU(),
        nn.Linear(32, output)
    )

  def forward(self, x):
    # CODE HERE (remove the pass afterwards)
    return self.layers(x)

model = MLP()

# CODE HERE (import torch summary)
from torchsummary import summary

# CODE HERE (print model summary)
summary(model, input_size=(1, 28, 28))

"""#Create the dataloaders"""

# CODE HERE (setup train_images, train_labels, test_images, test_labels as tensors)
train_images = torch.tensor(train_images, dtype=torch.float32)
train_labels = torch.tensor(train_labels, dtype=torch.long)
test_images = torch.tensor(test_images, dtype=torch.float32)
test_labels = torch.tensor(test_labels, dtype=torch.long)

# CODE HERE (print shape of all 4 tensors)
print(train_images.shape)
print(train_labels.shape)
print(test_images.shape)
print(test_labels.shape)

# CODE HERE (setup train_set and test_set as a TensorDataset)
train_set = torch.utils.data.TensorDataset(train_images, train_labels)
test_set = torch.utils.data.TensorDataset(test_images, test_labels)

# CODE HERE (setup train_loader and test_loader using DataLoader)
train_loader = DataLoader(train_images, batch_size=32, shuffle=False)
test_loader = DataLoader(test_images, batch_size=32, shuffle=False)

"""#Create the Loss Function & Optimizer

Tips:
- To determine what loss function to use, think about the type of task this model is supposed to perform, and recall which loss function we use for that task.
- Use the same optimizer which we used in the in-class lecture (we'll be using this one for most of our projects)
"""

# CODE HERE (loss_fn & optimizer)
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)

"""#Create the Train Loop

Recall all of the steps of the train_loop from the in-class project
"""

def train_loop(model, train_loader, loss_fn, optimizer, epochs):
  # CODE HERE (steps 2-3)
  train_loss = []
  model.train()

  for epoch in range(epochs):
    train_loss_epoch = 0

    for image, label in tqdm(train_loader, desc="Training Model"):
      # CODE HERE (steps 6-9)
      pred = model(image)
      loss = loss_fn(pred, label)
      optimizer.zero_grad()
      loss.backward()
      optimizer.step()
      train_loss_epoch += loss.item()

    # CODE HERE (steps 10-11) - note the indent is different
    train_loss.append(train_loss_epoch / len(train_loader))
    print(f'Epoch: {epoch+1} | Loss: {avg_loss:.4f}')

  return train_loss

# CODE HERE (run the train_loop by setting it to 'losses' variable)
losses = train_loop(model, train_loader, loss_fn, optimizer, epochs=10)

"""#Visualize the Loss Drop"""

# CODE HERE (plot the Loss vs. Epochs graph)
epoch_list = list(range(1, 11))
plt.plot(epoch_list, losses)
plt.title('Training Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.show()

"""#Creating the Testing Function"""

# CODE HERE (define accuracy function)
def accuracy(correct, total):
  return correct/total * 100

"""For the test_loop, again recall the steps we used from the in-class project (but with a few tweaks)"""

def test_loop(test_dataloader, model):
  # CODE HERE (steps 3-4)
  model.eval()
  correct = 0
  total = 0

  with torch.no_grad():
    for image, label in tqdm(test_dataloader, desc="Testing Model"):
      # CODE HERE (steps 7-8)
      pred = model(image)
      correct += (pred.argmax(1) == label).type(torch.float).sum().item()
      total += len(label)

    # CODE HERE (modified step 9) - print the # of correct predictions and # of total samples - note the indent is different
    print(f'Correct: {correct} / Total: {total}')

  # CODE HERE (create an 'accuracy' variable which calculates using your accuracy function)
  accuracy = accuracy(correct, total)

  return accuracy

# CODE HERE (run your test_loop by setting it to an accuracy variable)
accuracy = test_loop(test_loader, model)

"""Play around a bit with different images from the dataset and see how the model predicts using it"""

# CODE HERE (pick a random image index - set it to 'image' and plot it using plt)
plt.imshow(test_images[1].squeeze())
plt.title(f"Label: {test_labels[1]}")
plt.axis("off")
plt.show()

# below code will show model prediction based on the image you picked, you don't have to change this
with torch.no_grad():
  pred = model(test_images[image].to(torch.float32).unsqueeze(0)) # Add a dimension for batch
  print(num_to_letter[f"{pred.argmax(1).item()}"])

"""<img src="https://storage.googleapis.com/kaggle-datasets-images/3258/5337/0dade1b95b22cceac471b309fc8a8f63/dataset-cover.png" alt="Sign Language Dataset">

You're all done! Submit this file to Canvas
"""